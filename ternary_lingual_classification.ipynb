{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function: ReLU\n",
    "def ReLU(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function: sigmoid\n",
    "def sigmoid(mat):\n",
    "    return 1 / (1 + np.exp(-mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "def softmax(mat):\n",
    "    mat_exp = np.exp(mat)\n",
    "    return mat_exp / np.sum(mat_exp, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameters: w, b\n",
    "# z = w.T * x + b\n",
    "def init_params(dim):\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate gradients and cost\n",
    "def calc_grads_and_cost(w, b, X, Y):\n",
    "    # number of examples\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # z-value and y-hat vector\n",
    "    z = np.dot(w.T, X) + b\n",
    "    A = sigmoid(z)\n",
    "    \n",
    "    #A = softmax(ReLU(z))\n",
    "    \n",
    "    # cost\n",
    "    cost = - 1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
    "    \n",
    "    # gradients\n",
    "    #result = [[1 if z[j, i] > 0 else 0 for i in range(z.shape[1])] for j in range(z.shape[0])]\n",
    "    #result = [[1 for i in range(z.shape[1])] for j in range(z.shape[0])]\n",
    "    \n",
    "    #dz = np.asarray(result)\n",
    "    dz = A - Y\n",
    "    dw = 1 / m * np.dot(X, dz.T)\n",
    "    db = 1 / m * np.sum(dz)\n",
    "    cost = np.squeeze(cost)\n",
    "    #print(dw, db)\n",
    "    #print(A)\n",
    "    #print(z, dw, db)\n",
    "    \n",
    "    # store gradients\n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "def grad_desc(w, b, X, Y, num_iter, learning_rate):\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        grads, cost = calc_grads_and_cost(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        #print(w, b)\n",
    "        \n",
    "        # record costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            print(\"cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w, \"b\": b}\n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    Y_pred = np.zeros((1, m))\n",
    "    #print(w.shape)\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    #A = softmax(ReLU(np.dot(w.T, X) + b))\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0, i] <= 0.3333:\n",
    "            Y_pred[0, i] = 0\n",
    "        elif A[0, i] <= 0.6667:\n",
    "            Y_pred[0, i] = 0.5\n",
    "        else:\n",
    "            Y_pred[0, i] = 1\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iter, learning_rate):\n",
    "    w, b = init_params(X_train.shape[0])\n",
    "    params, grads, costs = grad_desc(w, b, X_train, Y_train, num_iter, learning_rate)\n",
    "    w = params[\"w\"]\n",
    "    b = params[\"b\"]\n",
    "    Y_pred_test = predict(w, b, X_test)\n",
    "    Y_pred_train = predict(w, b, X_train)\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_pred_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_pred_test - Y_test)) * 100))\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_pred_test, \n",
    "         \"Y_prediction_train\" : Y_pred_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iter}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after iteration 0: 0.693147\n",
      "cost after iteration 100: 0.652004\n",
      "cost after iteration 200: 0.645979\n",
      "cost after iteration 300: 0.641644\n",
      "cost after iteration 400: 0.638521\n",
      "cost after iteration 500: 0.636265\n",
      "cost after iteration 600: 0.634632\n",
      "cost after iteration 700: 0.633447\n",
      "cost after iteration 800: 0.632585\n",
      "cost after iteration 900: 0.631958\n",
      "cost after iteration 1000: 0.631499\n",
      "cost after iteration 1100: 0.631164\n",
      "cost after iteration 1200: 0.630918\n",
      "cost after iteration 1300: 0.630738\n",
      "cost after iteration 1400: 0.630606\n",
      "cost after iteration 1500: 0.630509\n",
      "cost after iteration 1600: 0.630437\n",
      "cost after iteration 1700: 0.630385\n",
      "cost after iteration 1800: 0.630346\n",
      "cost after iteration 1900: 0.630317\n",
      "train accuracy: 70.0 %\n",
      "test accuracy: 60.0 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'costs': [0.6931471805599454,\n",
       "  0.6520042926152847,\n",
       "  0.6459787941788377,\n",
       "  0.6416442205910403,\n",
       "  0.6385206458377501,\n",
       "  0.6362648331503258,\n",
       "  0.6346318853506802,\n",
       "  0.6334470512930337,\n",
       "  0.6325854371654551,\n",
       "  0.6319575686581291,\n",
       "  0.6314991681905127,\n",
       "  0.6311639257584329,\n",
       "  0.6309183815909325,\n",
       "  0.6307382952390465,\n",
       "  0.6306060614609168,\n",
       "  0.6305088648928132,\n",
       "  0.6304373577389095,\n",
       "  0.6303847090479975,\n",
       "  0.6303459189743581,\n",
       "  0.6303173227020841],\n",
       " 'Y_prediction_test': array([[1., 1., 1., 1., 1.]]),\n",
       " 'Y_prediction_train': array([[0.5, 0.5, 0.5, 1. , 1. ]]),\n",
       " 'w': array([[ 0.55956054],\n",
       "        [-0.13674106]]),\n",
       " 'b': -0.1392603212506096,\n",
       " 'learning_rate': 0.01,\n",
       " 'num_iterations': 2000}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr = [[1,2,3,4,5],\n",
    "    [6,7,8,9,10]]\n",
    "ytr = [0,1,0.5,1,0.5]\n",
    "xte = [[21,22,23,24,25],\n",
    "    [26,27,28,29,30]]\n",
    "yte = [1,0.5,0,0.5,1]\n",
    "xtr = np.asarray(xtr)\n",
    "ytr = np.asarray(ytr)\n",
    "xte = np.asarray(xte)\n",
    "yte = np.asarray(yte)\n",
    "model(xtr, ytr, xte, yte, 2000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 100)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import cycle, islice\n",
    "test_str = [\"Watashi no namae ha neko fubuki desu.\",\n",
    "            \"Kimi no koto ga daisuki da.\",\n",
    "            \"Watashi to tsukiatte kudasai!\",\n",
    "            \"Neko ha sonnani baka janai.\",\n",
    "            \"Aishiteru yo, oniisan!\",\n",
    "            \"Ore ga chuugokujin da kara, ramen ga suki da.\",\n",
    "            \"Wo de mingzi shi Ran Yuxiao.\",\n",
    "            \"Zuotian wo qule yitang bianlidian.\",\n",
    "            \"Meiyou shenme nenggou zudang wo de jiaobu.\",\n",
    "            \"Machunqing jiu shige da huaidan!\",\n",
    "            \"Zheshi diwu ju zhongwen le.\",\n",
    "            \"I don't like speaking English because of its difficulty\",\n",
    "            \"Logistic regression with a Neural Network mindset\",\n",
    "            \"There are only four English sentences in the training example.\",\n",
    "            \"The last one. Here we go.\",\n",
    "           \"Wo you kaishi shuo riyu le.\",\n",
    "           \"Raner wo shuodeshi zhongwen, hahaha.\",\n",
    "           \"Tianshang de xingxing bu shuohua, dishang de wawa jiao mama.\",\n",
    "           \"Kapai dashi Cuisite shi wo zuixihuan de yingxiong.\",\n",
    "           \"Kaado Masuta ha watashi no ichiban suki na chanpion desu.\",\n",
    "           \"Mou sugoshi dake de ii, mou sugoshi dake te ii~\",\n",
    "           \"Gakkou ni itte, jyoushi kousei wo mimashita.\",\n",
    "           \"First come, first served.\",\n",
    "           \"This sentence should not be terminated with a period\",\n",
    "           \"League of Legends is one of the most popular MOBA games in the world.\",\n",
    "           \"Star Guardian Ahri is one of my favorite skins in LoL!\",\n",
    "           \"Thanks for your generous help, StackOverflow!\"]\n",
    "ascii_list_orig = []\n",
    "for tr in test_str:\n",
    "    char_list = [char for char in tr]\n",
    "    ascii_list = list(map(ord, char_list))\n",
    "    ascii_list = list(islice(cycle(ascii_list), 100))\n",
    "    ascii_list = np.reshape(np.asarray(ascii_list), (1,-1))\n",
    "    if len(ascii_list_orig) == 0:\n",
    "        ascii_list_orig = ascii_list\n",
    "    else:\n",
    "        ascii_list_orig = np.vstack((ascii_list_orig, ascii_list))\n",
    "ascii_list_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = [[0,0,0,0,0,0,0.5,0.5,0.5,0.5,0.5,1,1,1,1,0.5,0.5,0.5,0.5,0,0,0,1,1,1,1,1]]\n",
    "test_label = np.asarray(test_label)\n",
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after iteration 0: 0.693147\n",
      "cost after iteration 100: 0.736976\n",
      "cost after iteration 200: 0.622312\n",
      "cost after iteration 300: 0.608742\n",
      "cost after iteration 400: 0.606088\n",
      "cost after iteration 500: 0.605370\n",
      "cost after iteration 600: 0.605013\n",
      "cost after iteration 700: 0.604687\n",
      "cost after iteration 800: 0.604334\n",
      "cost after iteration 900: 0.603959\n",
      "train accuracy: 83.33333333333334 %\n",
      "test accuracy: 83.33333333333334 %\n"
     ]
    }
   ],
   "source": [
    "#print(ascii_list_orig.T.shape, test_label.T.shape)\n",
    "d = model(ascii_list_orig.T, test_label, ascii_list_orig.T, test_label, 1000, 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_items = [\"Nani wo itteru no? Zenzen wakanai yo!\", #0\n",
    "                \"Wo buzhidao ni zai shuo shenme dongxi!\", #0.5\n",
    "                \"First come, first served.\", #1\n",
    "                \"That's unbelievable!\", #1\n",
    "                \"Kore ha nan desuka?\", #0\n",
    "                \"Kotori ha umi chan no koto ga daisuke desu!\", #0\n",
    "                 \"Wo shuode dou dui ba?\", #0.5\n",
    "                 \"Oi, omae tachi, nani wo itteru no?\", #0\n",
    "                 \"Kore kara mo yoroshiku ne~\", #0\n",
    "                 \"Going off work!\" #1\n",
    "                ]\n",
    "def run_test(my_test):\n",
    "    my_char_list = [char for char in my_test]\n",
    "    my_ascii_list = list(map(ord, my_char_list))\n",
    "    my_ascii_list = list(islice(cycle(my_ascii_list), 100))\n",
    "    my_ascii_list = np.reshape(np.asarray(my_ascii_list), (1,-1))\n",
    "    my_pred = predict(d[\"w\"], d[\"b\"], my_ascii_list.T)\n",
    "    print(\"y = \" + str(np.squeeze(my_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 1.0\n"
     ]
    }
   ],
   "source": [
    "my_pred = predict(d[\"w\"], d[\"b\"], my_ascii_list.T)\n",
    "print(\"y = \" + str(np.squeeze(my_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0.0\n",
      "y = 1.0\n",
      "y = 1.0\n",
      "y = 0.5\n",
      "y = 0.0\n",
      "y = 0.5\n",
      "y = 0.0\n",
      "y = 0.0\n",
      "y = 0.0\n",
      "y = 0.5\n"
     ]
    }
   ],
   "source": [
    "for my_test in my_test_items:\n",
    "    run_test(my_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
